# -*- coding: utf-8 -*-
"""
Streamlit app: Th·∫©m ƒë·ªãnh ph∆∞∆°ng √°n kinh doanh/ s·ª≠ d·ª•ng v·ªën (pasdv.docx)
"""
import io
import os
import re
import math
import json
import zipfile
import datetime as dt
from typing import Dict, Any, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st

# Docx parsing
try:
    from docx import Document
except Exception:
    Document = None

# Gemini
try:
    import google.generativeai as genai
except Exception:
    genai = None

# Plotly cho bi·ªÉu ƒë·ªì
try:
    import plotly.graph_objects as go
    import plotly.express as px
except Exception:
    go = None
    px = None

st.set_page_config(page_title="PASDV - Th·∫©m ƒë·ªãnh ph∆∞∆°ng √°n", page_icon="üíº", layout="wide")


# ========================== Helpers ==========================
FIELD_DEFAULTS = {
    "ten_khach_hang": "",
    "cccd": "",
    "noi_cu_tru": "",
    "so_dien_thoai": "",
    "muc_dich_vay": "",
    "tong_nhu_cau_von": 0.0,
    "von_doi_ung": 0.0,
    "so_tien_vay": 0.0,
    "lai_suat_nam": 10.0,
    "thoi_gian_vay_thang": 12,
    "ky_han_tra": "Th√°ng",
    "thu_nhap_thang": 0.0,
    "gia_tri_tsdb": 0.0,
    "tong_no_hien_tai": 0.0,
    "loi_nhuan_rong_nam": 0.0,
    "tong_von_dau_tu": 0.0,
}

def vnd_to_float(s: str) -> float:
    """Chuy·ªÉn chu·ªói ti·ªÅn t·ªá VN v·ªÅ float (h·ªó tr·ª£ d·∫•u . ngƒÉn c√°ch, , th·∫≠p ph√¢n)."""
    if s is None:
        return 0.0
    s = str(s)
    if "," in s and "." in s:
        s = s.replace(".", "").replace(",", ".")
    elif "," in s and "." not in s:
        s = s.replace(".", "")
        s = s.replace(",", ".")
    else:
        s = s.replace(".", "")

    s = s.replace("ƒë", "").replace("VND", "").replace("vnƒë", "").replace("‚Ç´", "").replace(" ", "")
    s = re.sub(r"[^\d\.\-]", "", s)
    try:
        return float(s) if s else 0.0
    except Exception:
        return 0.0

def format_vnd(amount: float) -> str:
    """ƒê·ªãnh d·∫°ng ti·ªÅn VND: 1.234.567"""
    try:
        return f"{float(amount):,.0f}".replace(",", ".")
    except Exception:
        return "0"

def format_vnd_float(amount: float) -> str:
    """ƒê·ªãnh d·∫°ng s·ªë th·∫≠p ph√¢n ki·ªÉu VN: 1.234.567,89"""
    try:
        s = f"{float(amount):,.2f}"
        s = s.replace(",", "_").replace(".", ",").replace("_", ".")
        return s
    except Exception:
        return "0,00"

def percent_to_float(s: str) -> float:
    """Chuy·ªÉn ƒë·ªïi chu·ªói ph·∫ßn trƒÉm sang s·ªë float; ch·∫•p nh·∫≠n '8,5' ho·∫∑c '8.5'."""
    if s is None:
        return 0.0
    s = str(s).replace(",", ".")
    m = re.search(r"(\d+(?:\.\d+)?)", s)
    return float(m.group(1)) if m else 0.0

def vn_money_input(label: str, value: float, key: Optional[str] = None, help: Optional[str] = None) -> float:
    """√î nh·∫≠p ti·ªÅn t·ªá ki·ªÉu VN: hi·ªÉn th·ªã 1.234.567 v√† parse l·∫°i v·ªÅ float."""
    raw = st.text_input(label, value=format_vnd(value), key=key, help=help)
    return float(vnd_to_float(raw))

def vn_percent_input(label: str, value: float, key: Optional[str] = None, help: Optional[str] = None) -> float:
    """√î nh·∫≠p ph·∫ßn trƒÉm linh ho·∫°t: cho ph√©p nh·∫≠p '8,5' ho·∫∑c '8.5'."""
    shown = f"{float(value):.2f}".replace(".", ",")
    raw = st.text_input(label, value=shown, key=key, help=help)
    return percent_to_float(raw)

def extract_from_docx(file_bytes: bytes) -> Dict[str, Any]:
    """ƒê·ªçc .docx PASDV v√† tr√≠ch xu·∫•t th√¥ng tin theo c·∫•u tr√∫c th·ª±c t·∫ø."""
    data = FIELD_DEFAULTS.copy()
    if Document is None:
        return data

    bio = io.BytesIO(file_bytes)
    doc = Document(bio)
    full_text = "\n".join([p.text for p in doc.paragraphs])

    lines = [line.strip() for line in full_text.split('\n') if line.strip()]
    full_text = "\n".join(lines)

    # === 1. TH√îNG TIN KH√ÅCH H√ÄNG ===
    ten_pattern1 = r"(?:\d+\.\s*)?H·ªç\s+v√†\s+t√™n\s*[:Ôºö]\s*([A-Z√Ä√Å·∫¢√É·∫†ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√Ç·∫¶·∫§·∫®·∫™·∫¨ƒê√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥][a-z√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫®·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµA-Z√Ä√Å·∫¢√É·∫†ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√Ç·∫¶·∫§·∫®·∫™·∫¨ƒê√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥\s]+)"
    m = re.search(ten_pattern1, full_text, flags=re.IGNORECASE)
    if m:
        data["ten_khach_hang"] = m.group(1).strip()
    else:
        ten_pattern2 = r"(?:√îng|B√†)\s*\((?:b√†|√¥ng)\)\s*[:Ôºö]\s*([A-Z√Ä√Å·∫¢√É·∫†ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√Ç·∫¶·∫§·∫®·∫™·∫¨ƒê√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥][a-z√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫®·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµA-Z√Ä√Å·∫¢√É·∫†ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√Ç·∫¶·∫§·∫®·∫™·∫¨ƒê√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥\s]+)"
        m = re.search(ten_pattern2, full_text, flags=re.IGNORECASE)
        if m:
            data["ten_khach_hang"] = m.group(1).strip()
    
    cccd_pattern = r"(?:CMND|CCCD)(?:\/(?:CCCD|CMND))?(?:\/h·ªô\s*chi·∫øu)?\s*[:Ôºö]\s*(\d{9,12})"
    m = re.search(cccd_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["cccd"] = m.group(1).strip()

    noi_cu_tru_pattern = r"N∆°i\s*c∆∞\s*tr√∫\s*[:Ôºö]\s*([^\n]+?)(?=\n|S·ªë\s*ƒëi·ªán\s*tho·∫°i|$)"
    m = re.search(noi_cu_tru_pattern, full_text, flags=re.IGNORECASE | re.DOTALL)
    if m:
        data["noi_cu_tru"] = m.group(1).strip()

    sdt_pattern = r"S·ªë\s*ƒëi·ªán\s*tho·∫°i\s*[:Ôºö]\s*(0\d{9,10})"
    m = re.search(sdt_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["so_dien_thoai"] = m.group(1).strip()

    # === 2. PH∆Ø∆†NG √ÅN S·ª¨ D·ª§NG V·ªêN ===
    muc_dich_pattern1 = r"M·ª•c\s*ƒë√≠ch\s*vay\s*[:Ôºö]\s*([^\n]+)"
    m = re.search(muc_dich_pattern1, full_text, flags=re.IGNORECASE)
    if m:
        data["muc_dich_vay"] = m.group(1).strip()
    else:
        muc_dich_pattern2 = r"V·ªën\s*vay\s*Agribank.*?[:Ôºö].*?(?:Th·ª±c\s*hi·ªán|S·ª≠\s*d·ª•ng\s*v√†o)\s*([^\n]+)"
        m = re.search(muc_dich_pattern2, full_text, flags=re.IGNORECASE | re.DOTALL)
        if m:
            data["muc_dich_vay"] = m.group(1).strip()[:200]

    tnc_pattern = r"(?:T·ªïng\s*nhu\s*c·∫ßu\s*v·ªën|1\.\s*T·ªïng\s*nhu\s*c·∫ßu\s*v·ªën)\s*[:Ôºö]\s*([\d\.,]+)"
    m = re.search(tnc_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["tong_nhu_cau_von"] = vnd_to_float(m.group(1))

    von_du_pattern = r"V·ªën\s*ƒë·ªëi\s*·ª©ng\s*(?:tham\s*gia)?[^\d]*([\d\.,]+)\s*ƒë·ªìng"
    m = re.search(von_du_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["von_doi_ung"] = vnd_to_float(m.group(1))

    so_tien_vay_pattern = r"V·ªën\s*vay\s*Agribank\s*(?:s·ªë\s*ti·ªÅn)?[:\s]*([\d\.,]+)\s*ƒë·ªìng"
    m = re.search(so_tien_vay_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["so_tien_vay"] = vnd_to_float(m.group(1))

    thoi_han_pattern = r"Th·ªùi\s*h·∫°n\s*vay\s*[:Ôºö]\s*(\d+)\s*th√°ng"
    m = re.search(thoi_han_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["thoi_gian_vay_thang"] = int(m.group(1))

    lai_suat_pattern = r"L√£i\s*su·∫•t\s*[:Ôºö]\s*([\d\.,]+)\s*%"
    m = re.search(lai_suat_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["lai_suat_nam"] = percent_to_float(m.group(1))

    # === 3. NGU·ªíN TR·∫¢ N·ª¢ & THU NH·∫¨P ===
    thu_nhap_du_an_pattern = r"T·ª´\s*ngu·ªìn\s*thu\s*c·ªßa\s*d·ª±\s*√°n[^\d]*([\d\.,]+)\s*ƒë·ªìng\s*/\s*th√°ng"
    m = re.search(thu_nhap_du_an_pattern, full_text, flags=re.IGNORECASE)
    thu_nhap_du_an = 0.0
    if m:
        thu_nhap_du_an = vnd_to_float(m.group(1))

    thu_nhap_luong_pattern = r"Thu\s*nh·∫≠p\s*t·ª´\s*l∆∞∆°ng\s*[:Ôºö]\s*([\d\.,]+)\s*ƒë·ªìng\s*/\s*th√°ng"
    m = re.search(thu_nhap_luong_pattern, full_text, flags=re.IGNORECASE)
    thu_nhap_luong = 0.0
    if m:
        thu_nhap_luong = vnd_to_float(m.group(1))

    tong_thu_nhap_pattern = r"T·ªïng\s*thu\s*nh·∫≠p\s*(?:·ªïn\s*ƒë·ªãnh)?\s*(?:h√†ng\s*)?th√°ng\s*[:Ôºö]\s*([\d\.,]+)\s*ƒë·ªìng"
    m = re.search(tong_thu_nhap_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["thu_nhap_thang"] = vnd_to_float(m.group(1))
    else:
        data["thu_nhap_thang"] = thu_nhap_luong + thu_nhap_du_an

    # === 4. T√ÄI S·∫¢N B·∫¢O ƒê·∫¢M ===
    tsdb_pattern1 = r"T√†i\s*s·∫£n\s*1[^\n]*Gi√°\s*tr·ªã\s*[:Ôºö]\s*([\d\.,]+)\s*ƒë·ªìng"
    m = re.search(tsdb_pattern1, full_text, flags=re.IGNORECASE | re.DOTALL)
    if m:
        data["gia_tri_tsdb"] = vnd_to_float(m.group(1))
    else:
        tsdb_pattern2 = r"Gi√°\s*tr·ªã\s*nh√†\s*d·ª±\s*ki·∫øn\s*mua\s*[:Ôºö]\s*([\d\.,]+)\s*ƒë·ªìng"
        m = re.search(tsdb_pattern2, full_text, flags=re.IGNORECASE)
        if m:
            data["gia_tri_tsdb"] = vnd_to_float(m.group(1))

    # === 5. TH√îNG TIN B·ªî SUNG ===
    loi_nhuan_pattern = r"L·ª£i\s*nhu·∫≠n\s*(?:r√≤ng)?\s*(?:nƒÉm)?[^\d]*([\d\.,]+)\s*ƒë·ªìng"
    m = re.search(loi_nhuan_pattern, full_text, flags=re.IGNORECASE)
    if m:
        data["loi_nhuan_rong_nam"] = vnd_to_float(m.group(1))
    elif thu_nhap_du_an > 0:
        data["loi_nhuan_rong_nam"] = thu_nhap_du_an * 12

    if data["tong_nhu_cau_von"] == 0 and (data["von_doi_ung"] + data["so_tien_vay"] > 0):
        data["tong_nhu_cau_von"] = data["von_doi_ung"] + data["so_tien_vay"]

    if data["tong_von_dau_tu"] == 0:
        data["tong_von_dau_tu"] = data["tong_nhu_cau_von"]

    if data["gia_tri_tsdb"] == 0 and data["tong_nhu_cau_von"] > 0:
        data["gia_tri_tsdb"] = data["tong_nhu_cau_von"]

    return data


def annuity_payment(principal: float, annual_rate_pct: float, months: int) -> float:
    r = annual_rate_pct / 100.0 / 12.0
    if months <= 0:
        return 0.0
    if r == 0:
        return principal / months
    pmt = principal * r * (1 + r) ** months / ((1 + r) ** months - 1)
    return pmt


def build_amortization(principal: float, annual_rate_pct: float, months: int, start_date: Optional[dt.date] = None) -> pd.DataFrame:
    if start_date is None:
        start_date = dt.date.today()
    r = annual_rate_pct / 100.0 / 12.0
    pmt = annuity_payment(principal, annual_rate_pct, months)

    schedule = []
    balance = principal
    for i in range(1, months + 1):
        interest = balance * r
        principal_pay = pmt - interest
        balance = max(0.0, balance - principal_pay)
        pay_date = start_date + dt.timedelta(days=30 * i)
        schedule.append({
            "K·ª≥": i,
            "Ng√†y thanh to√°n": pay_date.strftime("%d/%m/%Y"),
            "Ti·ªÅn l√£i": round(interest, 0),
            "Ti·ªÅn g·ªëc": round(principal_pay, 0),
            "T·ªïng ph·∫£i tr·∫£": round(pmt, 0),
            "D∆∞ n·ª£ c√≤n l·∫°i": round(balance, 0),
        })
    df = pd.DataFrame(schedule)
    return df

def style_schedule_table(df: pd.DataFrame) -> pd.DataFrame:
    """T√¥ m√†u b·∫£ng k·∫ø ho·∫°ch tr·∫£ n·ª£"""
    def color_row(row):
        if row['K·ª≥'] % 2 == 0:
            return ['background-color: #f0f8ff'] * len(row)
        else:
            return ['background-color: #ffffff'] * len(row)

    styled = df.style.apply(color_row, axis=1)
    styled = styled.format({
        'Ti·ªÅn l√£i': lambda x: format_vnd(x),
        'Ti·ªÅn g·ªëc': lambda x: format_vnd(x),
        'T·ªïng ph·∫£i tr·∫£': lambda x: format_vnd(x),
        'D∆∞ n·ª£ c√≤n l·∫°i': lambda x: format_vnd(x)
    })
    styled = styled.set_properties(**{
        'text-align': 'right',
        'font-size': '14px'
    }, subset=['Ti·ªÅn l√£i', 'Ti·ªÅn g·ªëc', 'T·ªïng ph·∫£i tr·∫£', 'D∆∞ n·ª£ c√≤n l·∫°i'])
    styled = styled.set_properties(**{
        'text-align': 'center'
    }, subset=['K·ª≥', 'Ng√†y thanh to√°n'])

    return styled


def compute_metrics(d: Dict[str, Any]) -> Dict[str, Any]:
    res = {}
    pmt = annuity_payment(d.get("so_tien_vay", 0.0), d.get("lai_suat_nam", 0.0), d.get("thoi_gian_vay_thang", 0))
    thu_nhap_thang = max(1e-9, d.get("thu_nhap_thang", 0.0))
    res["PMT_thang"] = pmt
    res["DSR"] = pmt / thu_nhap_thang if thu_nhap_thang > 0 else np.nan
    tong_nhu_cau = d.get("tong_nhu_cau_von", 0.0)
    von_doi_ung = d.get("von_doi_ung", 0.0)
    so_tien_vay = d.get("so_tien_vay", 0.0)
    gia_tri_tsdb = d.get("gia_tri_tsdb", 0.0)
    tong_no_hien_tai = d.get("tong_no_hien_tai", 0.0)
    loi_nhuan_rong_nam = d.get("loi_nhuan_rong_nam", 0.0)
    tong_von_dau_tu = d.get("tong_von_dau_tu", 0.0)

    res["E_over_C"] = (von_doi_ung / tong_nhu_cau) if tong_nhu_cau > 0 else np.nan
    res["LTV"] = (so_tien_vay / gia_tri_tsdb) if gia_tri_tsdb > 0 else np.nan
    thu_nhap_nam = thu_nhap_thang * 12.0
    res["Debt_over_Income"] = (tong_no_hien_tai + so_tien_vay) / max(1e-9, thu_nhap_nam)
    res["ROI"] = (loi_nhuan_rong_nam / max(1e-9, tong_von_dau_tu)) if tong_von_dau_tu > 0 else np.nan
    res["CFR"] = ((thu_nhap_thang - pmt) / thu_nhap_thang) if thu_nhap_thang > 0 else np.nan
    res["Coverage"] = (gia_tri_tsdb / max(1e-9, so_tien_vay)) if so_tien_vay > 0 else np.nan
    res["Phuong_an_hop_ly"] = math.isclose(tong_nhu_cau, von_doi_ung + so_tien_vay, rel_tol=0.02, abs_tol=1_000_000)

    score = 0.0
    if not np.isnan(res["DSR"]):
        score += max(0.0, 1.0 - min(1.0, res["DSR"])) * 0.25
    if not np.isnan(res["LTV"]):
        score += max(0.0, 1.0 - min(1.0, res["LTV"])) * 0.25
    if not np.isnan(res["E_over_C"]):
        score += min(1.0, res["E_over_C"] / 0.3) * 0.2
    if not np.isnan(res["CFR"]):
        score += max(0.0, min(1.0, (res["CFR"]))) * 0.2
    if not np.isnan(res["Coverage"]):
        score += min(1.0, (res["Coverage"] / 1.5)) * 0.1
    res["Score_AI_demo"] = round(score, 3)
    return res

def create_metrics_chart(metrics: Dict[str, Any]):
    """T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan cho c√°c ch·ªâ ti√™u t√†i ch√≠nh ch√≠nh"""
    if go is None or px is None:
        st.warning("Th∆∞ vi·ªán Plotly ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        return

    df_metrics = pd.DataFrame({
        "Ch·ªâ ti√™u": ["DSR", "LTV", "E/C", "Coverage", "CFR"],
        "Gi√° tr·ªã": [
            metrics.get("DSR", np.nan),
            metrics.get("LTV", np.nan),
            metrics.get("E_over_C", np.nan),
            metrics.get("Coverage", np.nan),
            metrics.get("CFR", np.nan),
        ],
        "Ng∆∞·ª°ng tham chi·∫øu": [0.8, 0.8, 0.2, 1.2, 0.0]
    })
    df_metrics = df_metrics.dropna(subset=['Gi√° tr·ªã']).reset_index(drop=True)

    if df_metrics.empty:
        st.info("Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì ch·ªâ ti√™u t√†i ch√≠nh.")
        return

    def get_color(row):
        metric = row['Ch·ªâ ti√™u']
        value = row['Gi√° tr·ªã']
        ref = row['Ng∆∞·ª°ng tham chi·∫øu']
        if metric in ["DSR", "LTV"]:
            return "green" if value <= ref else "red"
        elif metric in ["E/C", "Coverage", "CFR"]:
            return "green" if value >= ref else "red"
        return "gray"

    df_metrics['M√†u'] = df_metrics.apply(get_color, axis=1)
    df_metrics['Gi√° tr·ªã (%)'] = df_metrics['Gi√° tr·ªã'] * 100

    fig = px.bar(
        df_metrics,
        x="Ch·ªâ ti√™u",
        y="Gi√° tr·ªã (%)",
        color="M√†u",
        color_discrete_map={"green": "#28a745", "red": "#dc3545", "gray": "#6c757d"},
        text=df_metrics['Gi√° tr·ªã (%)'].apply(lambda x: f"{x:,.1f}%"),
        title="Bi·ªÉu ƒë·ªì Ch·ªâ ti√™u T√†i ch√≠nh (CADAP)",
        labels={"Gi√° tr·ªã (%)": "Gi√° tr·ªã (%)", "Ch·ªâ ti√™u": "Ch·ªâ ti√™u"},
    )

    for index, row in df_metrics.iterrows():
        metric = row['Ch·ªâ ti√™u']
        ref_value = row['Ng∆∞·ª°ng tham chi·∫øu'] * 100
        color = "#ffc107" if ref_value > 0 else "#007bff"

        if metric in ["DSR", "LTV"]:
            fig.add_shape(
                type="line",
                x0=index - 0.4, x1=index + 0.4, y0=ref_value, y1=ref_value,
                line=dict(color=color, width=2, dash="dash"),
                xref="x", yref="y",
                name=f"Ng∆∞·ª°ng {metric}"
            )
            fig.add_annotation(
                x=index, y=ref_value + 3,
                text=f"Max {ref_value:g}%", showarrow=False,
                font=dict(color=color, size=10),
            )
        elif metric in ["E/C", "Coverage"]:
            fig.add_shape(
                type="line",
                x0=index - 0.4, x1=index + 0.4, y0=ref_value, y1=ref_value,
                line=dict(color=color, width=2, dash="dash"),
                xref="x", yref="y",
                name=f"Ng∆∞·ª°ng {metric}"
            )
            fig.add_annotation(
                x=index, y=ref_value - 3,
                text=f"Min {ref_value:g}%", showarrow=False,
                font=dict(color=color, size=10),
            )

    fig.update_layout(
        showlegend=False,
        yaxis_title="Gi√° tr·ªã (%)",
        xaxis_title="Ch·ªâ ti√™u",
        hovermode="x unified"
    )

    st.plotly_chart(fig, use_container_width=True)


def gemini_analyze(d: Dict[str, Any], metrics: Dict[str, Any], model_name: str, api_key: str) -> str:
    if genai is None:
        return "Th∆∞ vi·ªán google-generativeai ch∆∞a ƒë∆∞·ª£c c√†i. Vui l√≤ng th√™m 'google-generativeai' v√†o requirements.txt."
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)

        d_formatted = {k: format_vnd(v) if isinstance(v, (int, float)) and k != 'lai_suat_nam' else v for k, v in d.items()}
        metrics_formatted = {
            k: (f"{v*100:,.1f}%"
                if k not in ["PMT_thang", "Debt_over_Income", "Score_AI_demo"] and not np.isnan(v)
                else format_vnd(v) if k == "PMT_thang"
                else f"{v:,.2f}")
            for k, v in metrics.items()
        }

        prompt = f"""
B·∫°n l√† chuy√™n vi√™n t√≠n d·ª•ng. Ph√¢n t√≠ch h·ªì s∆° vay sau (JSON) v√† ƒë∆∞a ra ƒë·ªÅ xu·∫•t "Cho vay" / "Cho vay c√≥ ƒëi·ªÅu ki·ªán" / "Kh√¥ng cho vay" k√®m gi·∫£i th√≠ch ng·∫Øn g·ªçn (<=200 t·ª´).
JSON ƒë·∫ßu v√†o:
Kh√°ch h√†ng & ph∆∞∆°ng √°n: {json.dumps(d_formatted, ensure_ascii=False)}
Ch·ªâ ti√™u t√≠nh to√°n: {json.dumps(metrics_formatted, ensure_ascii=False)}
Ng∆∞·ª°ng tham chi·∫øu:
- DSR ‚â§ 0.8; LTV ‚â§ 0.8; E/C ‚â• 0.2; CFR > 0; Coverage > 1.2.
- N·∫øu th√¥ng tin thi·∫øu, h√£y n√™u gi·∫£ ƒë·ªãnh r√µ r√†ng.
"""
        resp = model.generate_content(prompt)
        return resp.text or "(Kh√¥ng c√≥ n·ªôi dung t·ª´ Gemini)"
    except Exception as e:
        return f"
